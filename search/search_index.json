{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Sergio Esteban Romero","text":""},{"location":"#about","title":"About","text":"<p>Hi! My name is Sergio. I am currently working as a PhD student at @ THAU-ETSIT-UPM Universidad Polit\u00e9cnica de Madrid. When I'm not diving deep into the world of research, you can catch me geeking out over Artificial Intelligence, pondering chess strategies, grooving to my favorite tunes, or lost in the captivating world of movies. My goal is to dive into the mind-bending world of multimodal domain approaches and unravel the mysteries of the universe, one data point at a time. \ud83d\ude80\ud83e\udde0\u265f\ufe0f\ud83c\udfb5\ud83c\udfa5\ud83c\udfc6</p>"},{"location":"#contact","title":"Contact","text":"<ul> <li>:phone: : 663480823</li> <li>:mailbox_closed: : sergio.estebanro(at)alumnos.upm.es</li> </ul>"},{"location":"publications/","title":"THAURUS: An innovative multimodal chatbot based on the next generation of conversational AI","text":"<p>The next generation of conversational AI has brought incredible capabilities such as high contextuality, naturalness, multimodality, and extended knowledge, but also important challenges such as high user expectations, high latencies, large computational requirements, as well as more subtle problems such as mismatch on existing databases for fine-tuning purposes, difficulties for pre-trained LLMs models to handle dialogue interactions, and the integration of multimodal capabilities.</p> <p>This paper describes the architecture, methodology, and results of our THAURUS chatbot developed for the Alexa Prize Socialbot Grand Challenge (SGC5). Our proposal relies on several innovative ideas to take advantage of existing LLMs to create engaging user experiences that are capable of handling real users in a scalable way and without compromising the competition rules. Different SotA dialogue generators were fine-tuned and incorporated to give variability and handling the wide range of topic conversations; we also developed mechanisms to control the quality of the responses (e.g., detecting and handling toxic interactions, keeping topic coherence, and increasing engagement by providing up-to-date information in a conversational style).</p> <p>In addition, our system extends the capabilities of the Cobot architecture by incorporating modules to automatically generate images, provide voice cloning capabilities with fictional characters, serve contextual sounds for detected entities in the dialogue, better capitalization and punctuation capabilities, and to provide natural expressions of interest.</p> <p>Finally, we also included a trained generative selector and a reference-free model for automatic evaluation of turns that could reduce latencies and complement the ranker\u2019s capabilities to select the best generative answer.</p> <pre><code>@Inproceedings{Madrid2023,\nauthor = {Universidad Polit\u00e9cnica de Madrid},\ntitle = {THAURUS: An innovative multimodal chatbot based on the next generation of conversational AI},\nyear = {2023},\nurl = {https://www.amazon.science/alexa-prize/proceedings/thaurus-an-innovative-multimodal-chatbot-based-on-the-next-generation-of-conversational-ai},\nbooktitle = {Alexa Prize SocialBot Grand Challenge 5 Proceedings},\n}\n</code></pre>"},{"location":"publications/#gth-upm-at-detoxis-iberlef-2021-automatic-detection-of-toxic-comments-in-social-networks","title":"GTH-UPM at DETOXIS-IberLEF 2021: Automatic Detection of Toxic Comments in Social Networks","text":"<p>Sadly, the presence of toxic messages on social networks, whether in the form of stereotypes, sarcasm, mockery, insult, inappropriate language, aggressiveness, intolerance, or typical of hate speech against immigrants and / or women, among others, is relatively frequent. This presence should not be ignored by the scientific community, since it is their responsibility to develop tools and systems that allow their automatic detection and elimination. In this paper, we present an exploratory analysis in which different deep learning (DL) models for the detection of toxic expressions have been evaluated on the DETOXIS IberLEF 2021 challenge using the official release of the NewsCom-TOX corpus. Particularly, we compare traditional RNN and state-of-the-art transformer models. Our experiments confirmed that optimum performance can be obtained from transformer models. Specifically, top performance was achieved by fine tuning a BETO model (the pre-trained BERT model for the Spanish language from the Universidad de Chile) for the toxicity detection tasks. Another contribution of this analysis is the validation of the proposed method for adding task-specific vocabulary (new tokens) that could help</p> <pre><code>@inproceedings{inproceedings,\nauthor = {Romero, Sergio and Kleinlein, Ricardo and Luna Jim\u00e9nez, Cristina and Montero, Juan and Fern\u00e1ndez-Mart\u00ednez, Fernando},\nyear = {2021},\nmonth = {06},\npages = {},\ntitle = {GTH-UPM at DETOXIS-IberLEF 2021: Automatic Detection of Toxic Comments in Social Networks}\n}\n</code></pre>"}]}